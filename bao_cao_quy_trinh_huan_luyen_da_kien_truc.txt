4.2. QUY TRÌNH HUẤN LUYỆN ĐA KIẾN TRÚC VÀ TỐI ƯU HÓA THỰC NGHIỆM

Quy trình huấn luyện đa kiến trúc là một chiến lược quan trọng để so sánh và lựa chọn mô hình tốt nhất cho bài toán cụ thể. Trong đề tài này, ba mô hình backbone khác nhau (EfficientNet-B0, ResNet-50, MobileNetV3-Large) được huấn luyện độc lập với cùng một quy trình và cấu hình để đảm bảo tính công bằng trong so sánh. Quy trình này được thiết kế với nhiều cơ chế kiểm tra, tối ưu hóa, và quản lý tài nguyên để đảm bảo tính ổn định, hiệu quả và có thể tái tạo.

4.2.1. Cơ chế kiểm tra ràng buộc (Dependency Validation)

a) Tầm quan trọng của Dependency Validation:

Trước khi bắt đầu quá trình huấn luyện, việc kiểm tra các dependencies (phụ thuộc) là bước quan trọng để đảm bảo tất cả các thành phần cần thiết đã được khởi tạo và sẵn sàng. Điều này giúp phát hiện sớm các lỗi thiếu sót và tránh lãng phí thời gian khi training bị dừng giữa chừng do thiếu dependencies.

b) Các Dependencies được kiểm tra:

1. Kiểm tra Training Functions:

Trước khi bắt đầu training, hệ thống kiểm tra xem các hàm training cơ bản đã được định nghĩa chưa:

- `train_epoch`: Hàm thực hiện training một epoch
- `validate`: Hàm thực hiện validation một epoch
- `evaluate_on_loader`: Hàm đánh giá mô hình trên một data loader

Cơ chế kiểm tra:
```python
if 'train_epoch' not in globals() or 'validate' not in globals():
    raise NameError("train_epoch và validate chưa được định nghĩa. 
                    Vui lòng chạy Cell 18 (Training Functions) trước!")
```

Nếu thiếu, hệ thống sẽ dừng ngay và thông báo rõ ràng cần chạy cell nào trước.

2. Kiểm tra Model Architecture:

Hệ thống kiểm tra xem class `MushroomClassifier` đã được định nghĩa chưa:

```python
if 'MushroomClassifier' not in globals():
    raise NameError("MushroomClassifier chưa được định nghĩa. 
                    Vui lòng chạy Cell 15 (Model Architecture) trước!")
```

Điều này đảm bảo mô hình có thể được khởi tạo trước khi training.

3. Kiểm tra Data Loaders:

Hệ thống kiểm tra xem các data loaders (train_loader, val_loader, test_loader) đã được tạo chưa:

```python
if 'test_loader' not in globals():
    print("[ERROR] test_loader chưa được định nghĩa! 
           Vui lòng chạy Cell 10 (Data Loading) trước!")
```

Điều này đảm bảo có dữ liệu để train và evaluate.

4. Kiểm tra Configuration:

Hệ thống kiểm tra xem các cấu hình cần thiết đã được thiết lập chưa:
- `TRAIN_CONFIG`: Cấu hình training (batch size, learning rate, epochs, v.v.)
- `class_weights`: Trọng số cho các lớp
- `ALL_CLASSES`: Danh sách các lớp
- `device`: Thiết bị tính toán (GPU/CPU)

c) Lợi ích của Dependency Validation:

- Phát hiện lỗi sớm: Phát hiện ngay khi thiếu dependencies, không phải đợi đến khi training bắt đầu
- Thông báo rõ ràng: Chỉ ra chính xác cần chạy cell nào để khắc phục
- Tiết kiệm thời gian: Tránh lãng phí thời gian khi training bị dừng giữa chừng
- Đảm bảo tính nhất quán: Đảm bảo tất cả các thành phần đã được khởi tạo đúng cách

d) Xử lý lỗi trong Training:

Ngoài việc kiểm tra dependencies trước khi bắt đầu, hệ thống còn có cơ chế xử lý lỗi trong quá trình training:

1. Try-Except Blocks:

Mỗi bước quan trọng trong training được bọc trong try-except:
- Tạo model: Nếu lỗi, thông báo và dừng
- Khởi tạo optimizer: Nếu lỗi, thông báo và dừng
- Training loop: Nếu lỗi, cố gắng lưu kết quả đã train được
- Lưu model: Nếu lỗi, thông báo nhưng không dừng toàn bộ quá trình

2. Graceful Degradation:

Khi có lỗi không nghiêm trọng (như lỗi lưu plots), hệ thống vẫn tiếp tục:
- Lưu model checkpoint ngay cả khi có lỗi nhỏ
- Ghi log lỗi để debug sau
- Không làm dừng toàn bộ quá trình training

4.2.2. Chiến lược tối ưu hóa siêu tham số (Hyperparameter Tuning)

a) Khái niệm về Hyperparameters:

Hyperparameters (siêu tham số) là các tham số được thiết lập trước khi bắt đầu training, không được học từ dữ liệu. Việc lựa chọn hyperparameters phù hợp ảnh hưởng lớn đến hiệu suất của mô hình. Trong đề tài này, các hyperparameters được tối ưu hóa dựa trên kinh nghiệm và thực nghiệm.

b) Các Hyperparameters chính:

1. Batch Size:

- Giá trị: 192 (tự động tối ưu theo GPU VRAM)
- Cơ chế tối ưu:
  + A6000 (48GB VRAM): batch_size = 192
  + RTX 3090 (24GB VRAM): batch_size = 96
  + CPU mode: batch_size = 16
- Lý do: Batch size lớn giúp training ổn định hơn và tận dụng tốt GPU parallelism, nhưng cần đủ VRAM

2. Learning Rate:

- Base Learning Rate: 0.001
- Differential Learning Rates:
  + Backbone LR: 0.0001 (base_lr × 0.1) - Tinh chỉnh nhẹ nhàng các trọng số pre-trained
  + Classifier LR: 0.001 (base_lr × 1.0) - Học nhanh các lớp mới
- Lý do: Backbone đã được pre-trained nên cần learning rate thấp hơn để bảo toàn features đã học, trong khi classifier cần học nhanh hơn

3. Number of Epochs:

- Giá trị: 50 epochs (tối đa)
- Early Stopping: Patience = 5 epochs
- Thực tế: Mô hình thường dừng sớm ở khoảng 30-40 epochs do early stopping
- Lý do: Đủ epochs để mô hình hội tụ nhưng không quá nhiều để tránh lãng phí thời gian

4. Learning Rate Scheduler:

- Type: ReduceLROnPlateau
- Mode: 'min' (giảm khi validation loss không giảm)
- Factor: 0.5 (giảm LR một nửa mỗi lần)
- Patience: 5 epochs
- Lý do: Tự động điều chỉnh learning rate khi mô hình gần hội tụ, giúp tinh chỉnh tốt hơn

5. Weight Decay (L2 Regularization):

- Giá trị: 1e-4 (0.0001)
- Lý do: Giảm overfitting bằng cách phạt các trọng số lớn, nhưng không quá mạnh để không ảnh hưởng đến learning

6. Label Smoothing:

- Giá trị: 0.1 (10%)
- Lý do: Chống overfitting và tăng khả năng tổng quát hóa bằng cách làm "mềm" nhãn mục tiêu

7. Class Weights Multiplier:

- Poisonous Weight Multiplier: 4.0x (tăng từ 2.0x)
- Lý do: Tăng cường khả năng phát hiện nấm độc (recall >= 90%), đảm bảo an toàn

c) Quy trình tối ưu hóa:

1. Baseline Configuration:

Bắt đầu với cấu hình baseline dựa trên best practices:
- Learning rate: 0.001 (phổ biến cho Adam optimizer)
- Batch size: Tối đa theo VRAM
- Epochs: 50 với early stopping

2. Fine-tuning dựa trên kết quả:

Sau khi có kết quả ban đầu, điều chỉnh:
- Tăng Poisonous Weight Multiplier từ 2.0x lên 4.0x để cải thiện recall cho nấm độc
- Giữ nguyên các hyperparameters khác vì đã hoạt động tốt

3. Validation-based Tuning:

Sử dụng validation accuracy để đánh giá:
- Nếu validation accuracy không cải thiện: Learning rate được tự động giảm
- Nếu validation accuracy không cải thiện trong 5 epochs: Training dừng sớm

d) Kết quả tối ưu hóa:

Sau quá trình tối ưu hóa, cấu hình cuối cùng cho kết quả tốt nhất:
- ResNet-50: Test Accuracy 91.59% với cấu hình trên
- EfficientNet-B0: Test Accuracy 88.33%
- MobileNetV3-Large: Test Accuracy 87.64%

Các hyperparameters này được áp dụng đồng nhất cho cả ba models để đảm bảo so sánh công bằng.

4.2.3. Cơ chế dừng sớm và lưu trữ trạng thái tốt nhất (Early Stopping & Best Model Saving)

a) Khái niệm về Early Stopping:

Early Stopping là một kỹ thuật regularization quan trọng để ngăn chặn overfitting bằng cách dừng training khi hiệu suất trên validation set không còn cải thiện. Điều này không chỉ giúp tránh overfitting mà còn tiết kiệm thời gian và tài nguyên tính toán.

b) Cơ chế Early Stopping trong đề tài:

1. Patience:

- Giá trị: 5 epochs
- Ý nghĩa: Chờ đợi 5 epochs liên tiếp mà validation accuracy không cải thiện trước khi dừng
- Lý do: Đủ thời gian để mô hình có cơ hội cải thiện nhưng không quá lâu để tránh lãng phí

2. Monitoring Metric:

- Metric: Validation Accuracy
- Lý do: Validation accuracy phản ánh khả năng tổng quát hóa của mô hình tốt hơn training accuracy

3. Quy trình hoạt động:

Sau mỗi epoch:
- Tính validation accuracy
- So sánh với best_val_acc hiện tại
- Nếu cải thiện:
  + Cập nhật best_val_acc
  + Cập nhật best_epoch
  + Reset patience_counter về 0
  + Lưu best_model_state
- Nếu không cải thiện:
  + Tăng patience_counter lên 1
  + Nếu patience_counter >= patience (5): Dừng training

4. Thông báo Early Stopping:

Khi early stopping được kích hoạt:
- In thông báo rõ ràng: "Early stopping tại epoch X (không cải thiện trong 5 epochs)"
- Ghi log: Lưu thông tin vào log file
- Hiển thị best epoch và best validation accuracy

c) Kết quả Early Stopping thực tế:

**ResNet-50**:
- Best Epoch: 34
- Epochs Trained: 39 (dừng sớm sau 5 epochs không cải thiện)
- Best Val Accuracy: 93.39%
- **Phân tích**: Mô hình đạt best performance ở epoch 34, sau đó không cải thiện thêm

**EfficientNet-B0**:
- Best Epoch: 26
- Epochs Trained: 31 (dừng sớm)
- Best Val Accuracy: 88.41%
- **Phân tích**: Mô hình hội tụ nhanh hơn, đạt best ở epoch 26

**MobileNetV3-Large**:
- Best Epoch: 25
- Epochs Trained: 30 (dừng sớm)
- Best Val Accuracy: 87.73%
- **Phân tích**: Mô hình nhẹ nhất, hội tụ nhanh nhất

d) Lưu trữ Best Model:

1. Cơ chế lưu trữ:

Sau mỗi epoch có validation accuracy cải thiện:
- Lưu toàn bộ state của mô hình vào best_model_state
- Bao gồm: model weights, optimizer state, epoch, metrics

2. Nội dung Checkpoint:

Checkpoint bao gồm:
- `epoch`: Số epoch tốt nhất
- `model_state_dict`: Tất cả weights và biases của mô hình
- `optimizer_state_dict`: Trạng thái của optimizer (momentum, learning rate, v.v.)
- `best_val_acc`: Validation accuracy tốt nhất
- `train_losses`, `train_accs`: Lịch sử training
- `val_losses`, `val_accs`: Lịch sử validation
- `backbone`, `num_classes`: Thông tin kiến trúc
- `poisonous_weight_multiplier`: Hệ số nhân class weights
- `training_timestamp`: Thời gian training

3. File Naming:

- Standard: `best_model_{backbone_name}.pth`
- Improved: `best_model_{backbone_name}_improved.pth` (khi retrain với weights 4.0x)

4. Load Best Model:

Sau khi training hoàn tất (hoặc early stopping):
- Load best_model_state vào mô hình
- Đảm bảo sử dụng mô hình tốt nhất, không phải mô hình cuối cùng (có thể đã overfit)

e) Lợi ích của Early Stopping và Best Model Saving:

- Tránh overfitting: Dừng trước khi mô hình học quá mức trên training data
- Tiết kiệm thời gian: Không cần chờ đến hết số epochs đã đặt
- Tự động chọn best model: Luôn sử dụng mô hình tốt nhất
- Có thể tiếp tục training: Có thể load checkpoint và tiếp tục training nếu cần

4.2.4. Quản lý tài nguyên và giải phóng bộ nhớ (Memory Management)

a) Tầm quan trọng của Memory Management:

Trong quá trình training nhiều models, việc quản lý memory hiệu quả là cực kỳ quan trọng để:
- Tránh Out of Memory (OOM) errors
- Cho phép train nhiều models liên tiếp
- Tận dụng tối đa tài nguyên GPU
- Đảm bảo tính ổn định của hệ thống

b) Các kỹ thuật Memory Management:

1. Giải phóng Memory sau mỗi Model:

Sau khi training xong một backbone model:
```python
# Xóa model, optimizer, scheduler
del model, optimizer, scheduler
del best_model_state

# Garbage collection
gc.collect()

# Xóa CUDA cache
if device.type == 'cuda':
    torch.cuda.empty_cache()
```

Lợi ích:
- Giải phóng GPU memory ngay lập tức
- Chuẩn bị memory cho model tiếp theo
- Tránh memory leak giữa các lần training

2. Batch Processing:

- Xử lý dữ liệu theo batch thay vì load toàn bộ vào memory
- Batch size được tối ưu theo VRAM: 192 cho A6000, 96 cho RTX 3090
- Lợi ích: Không cần load toàn bộ dataset vào memory cùng lúc

3. Mixed Precision Training (FP16):

- Sử dụng FP16 thay vì FP32 cho phần lớn các phép tính
- Giảm memory usage ~50%
- Cho phép sử dụng batch size lớn hơn
- Lợi ích: Tận dụng tốt hơn GPU memory

4. Gradient Accumulation (Tùy chọn):

- Tích lũy gradients qua nhiều batches trước khi update
- Cho phép mô phỏng batch size lớn hơn mà không cần nhiều memory
- Trong đề tài: gradient_accumulation_steps = 1 (không tích lũy)
- Có thể tăng nếu gặp vấn đề memory

5. Persistent Workers:

- `persistent_workers=True`: Giữ workers sống giữa các epochs
- Giảm overhead của việc tạo workers mới
- Tuy nhiên, cần quản lý memory của workers cẩn thận

6. Pin Memory:

- `pin_memory=True`: Chỉ bật cho GPU
- Tăng tốc transfer data từ CPU sang GPU
- Sử dụng một phần CPU memory nhưng tăng tốc đáng kể

c) Memory Usage thực tế:

**ResNet-50 trên A6000 (48GB VRAM)**:
- Model size: ~25MB (weights)
- Training memory: ~8-10GB VRAM (với batch size 192, FP16)
- Validation memory: ~6-8GB VRAM (không tính gradients)
- Peak memory: ~12GB VRAM

**EfficientNet-B0**:
- Model size: ~5MB
- Training memory: ~6-8GB VRAM
- Peak memory: ~10GB VRAM

**MobileNetV3-Large**:
- Model size: ~4MB
- Training memory: ~5-7GB VRAM
- Peak memory: ~9GB VRAM

d) Cleanup Strategy:

1. Sau mỗi Training Session:

- Xóa tất cả variables liên quan đến model
- Garbage collection
- Clear CUDA cache
- Reset memory counters

2. Giữa các Models:

- Đảm bảo memory được giải phóng hoàn toàn trước khi train model tiếp theo
- Kiểm tra memory usage nếu cần

3. Error Handling:

- Ngay cả khi có lỗi, vẫn cố gắng giải phóng memory
- Tránh memory leak khi training bị dừng đột ngột

e) Monitoring Memory:

- Có thể monitor memory usage bằng `nvidia-smi` hoặc `torch.cuda.memory_allocated()`
- Log memory usage nếu cần debug
- Cảnh báo nếu memory usage quá cao

4.2.5. Phân tích định lượng và so sánh (Results Summary)

a) Tổng quan về Results Summary:

Sau khi training mỗi model, hệ thống tự động tạo một bản tóm tắt kết quả (Results Summary) bao gồm tất cả các metrics quan trọng. Điều này cho phép so sánh dễ dàng giữa các models và phân tích hiệu suất.

b) Nội dung Results Summary:

1. Training Configuration:

- Backbone name: Tên mô hình (efficientnet_b0, resnet50, mobilenet_v3_large)
- Timestamp: Thời gian training
- Batch size: 192
- Number of epochs: 50 (tối đa)
- Learning rate: 0.001
- Number of workers: 32
- Mixed precision: True/False

2. Training Results:

- Best Validation Accuracy: Accuracy tốt nhất trên validation set
- Test Accuracy: Accuracy trên test set
- Best Epoch: Epoch đạt best validation accuracy
- Epochs Trained: Số epochs thực tế đã train (có thể < 50 do early stopping)
- Training Time: Thời gian training tính bằng phút

3. Final Metrics:

- Train Loss: Loss cuối cùng trên training set
- Train Accuracy: Accuracy cuối cùng trên training set
- Validation Loss: Loss cuối cùng trên validation set
- Validation Accuracy: Accuracy cuối cùng trên validation set

4. Classification Metrics:

- Macro Average: Precision, Recall, F1-Score (trung bình công bằng)
- Weighted Average: Precision, Recall, F1-Score (có trọng số)
- Per-Class Metrics: Precision, Recall, F1-Score cho từng lớp

c) Kết quả thực tế của 3 Models:

**ResNet-50** (Model tốt nhất):
- Test Accuracy: **91.59%**
- Best Val Accuracy: 93.39%
- Best Epoch: 34
- Epochs Trained: 39
- Training Time: 7.60 phút
- Macro Avg F1-Score: 90.57%
- Weighted Avg F1-Score: 91.59%

**EfficientNet-B0**:
- Test Accuracy: **88.33%**
- Best Val Accuracy: 88.41%
- Best Epoch: 26
- Epochs Trained: 31
- Training Time: 7.13 phút
- Macro Avg F1-Score: 88.09%
- Weighted Avg F1-Score: 88.34%

**MobileNetV3-Large**:
- Test Accuracy: **87.64%**
- Best Val Accuracy: 87.73%
- Best Epoch: 25
- Epochs Trained: 30
- Training Time: 6.09 phút (nhanh nhất)
- Macro Avg F1-Score: 87.54%
- Weighted Avg F1-Score: 87.77%

d) Lưu trữ Results Summary:

1. JSON Format:

- File: `training_summary_{backbone_name}_{timestamp}.json`
- Lưu tại: `results/reports/`
- Encoding: UTF-8
- Mục đích: Dễ load và phân tích bằng code

2. Persistence:

- Results được lưu vào files để persist giữa các sessions
- Có thể load lại khi restart kernel
- Hàm `load_results_summary_from_files()` tự động load từ files

3. Comprehensive Report:

- File tổng hợp: `comprehensive_evaluation_report_{timestamp}.json`
- Bao gồm kết quả của tất cả models
- So sánh và phân tích tổng thể

e) Phân tích Results Summary:

1. Accuracy Comparison:

- ResNet-50 có accuracy cao nhất (91.59%)
- EfficientNet-B0 cân bằng giữa accuracy và efficiency (88.33%)
- MobileNetV3-Large nhanh nhất nhưng accuracy thấp hơn (87.64%)

2. Training Efficiency:

- MobileNetV3-Large: Nhanh nhất (6.09 phút) nhưng accuracy thấp nhất
- EfficientNet-B0: Cân bằng (7.13 phút, 88.33%)
- ResNet-50: Chậm nhất (7.60 phút) nhưng accuracy cao nhất

3. Convergence Analysis:

- MobileNetV3-Large: Hội tụ nhanh nhất (best epoch 25)
- EfficientNet-B0: Hội tụ nhanh (best epoch 26)
- ResNet-50: Hội tụ chậm hơn (best epoch 34) nhưng đạt accuracy cao hơn

4.2.6. So sánh giữa 3 mô hình (Comparison between 3 Models)

a) Mục đích của So sánh:

Việc so sánh giữa ba mô hình backbone khác nhau cho phép:
- Đánh giá điểm mạnh và điểm yếu của từng kiến trúc
- Lựa chọn mô hình phù hợp nhất cho bài toán cụ thể
- Hiểu rõ trade-off giữa accuracy và efficiency
- Đưa ra khuyến nghị cho các ứng dụng thực tế

b) So sánh về Accuracy:

1. Overall Accuracy:

| Model | Test Accuracy | Best Val Accuracy | Chênh lệch |
|-------|---------------|------------------|------------|
| **ResNet-50** | **91.59%** | 93.39% | 1.80% |
| EfficientNet-B0 | 88.33% | 88.41% | 0.08% |
| MobileNetV3-Large | 87.64% | 87.73% | 0.09% |

**Phân tích**:
- ResNet-50 có accuracy cao nhất, vượt trội 3.26% so với model thứ hai
- EfficientNet-B0 và MobileNetV3-Large có accuracy gần nhau
- Chênh lệch giữa Val và Test accuracy nhỏ cho thấy khả năng tổng quát hóa tốt

2. Macro Average Metrics:

| Model | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| **ResNet-50** | **90.64%** | **90.64%** | **90.57%** |
| EfficientNet-B0 | 87.63% | 88.84% | 88.09% |
| MobileNetV3-Large | 87.49% | 88.38% | 87.54% |

**Phân tích**:
- ResNet-50 có metrics tốt nhất trên tất cả các chỉ số
- EfficientNet-B0 có recall cao nhất (88.84%) sau ResNet-50
- MobileNetV3-Large có metrics thấp nhất nhưng vẫn chấp nhận được

3. Weighted Average Metrics:

| Model | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| **ResNet-50** | **91.67%** | **91.59%** | **91.59%** |
| EfficientNet-B0 | 88.70% | 88.33% | 88.34% |
| MobileNetV3-Large | 88.60% | 87.64% | 87.77% |

**Phân tích**: Weighted averages phản ánh performance tổng thể trên toàn bộ dataset, ResNet-50 vẫn dẫn đầu.

c) So sánh về Efficiency:

1. Training Time:

| Model | Training Time (min) | Epochs Trained | Time per Epoch (min) |
|-------|---------------------|----------------|---------------------|
| MobileNetV3-Large | **6.09** | 30 | 0.203 |
| EfficientNet-B0 | 7.13 | 31 | 0.230 |
| ResNet-50 | 7.60 | 39 | 0.195 |

**Phân tích**:
- MobileNetV3-Large nhanh nhất (6.09 phút)
- ResNet-50 chậm nhất nhưng train nhiều epochs hơn (39 vs 30-31)
- Time per epoch của ResNet-50 thực ra nhanh nhất (0.195 min/epoch)

2. Efficiency Score (Accuracy / Time):

| Model | Test Accuracy (%) | Training Time (min) | Efficiency Score |
|-------|-------------------|---------------------|-----------------|
| MobileNetV3-Large | 87.64 | 6.09 | **0.1439** |
| EfficientNet-B0 | 88.33 | 7.13 | 0.1240 |
| ResNet-50 | 91.59 | 7.60 | 0.1206 |

**Phân tích**:
- MobileNetV3-Large có efficiency score cao nhất (accuracy/time)
- ResNet-50 có efficiency thấp nhất nhưng accuracy cao nhất
- Trade-off rõ ràng: accuracy cao hơn cần thời gian nhiều hơn

3. Model Size:

| Model | Model Size (MB) | Parameters (approx) |
|-------|-----------------|---------------------|
| MobileNetV3-Large | ~4 | ~5.5M |
| EfficientNet-B0 | ~5 | ~5.3M |
| ResNet-50 | ~25 | ~25M |

**Phân tích**:
- MobileNetV3-Large và EfficientNet-B0 nhẹ, phù hợp deployment
- ResNet-50 nặng hơn nhưng có nhiều parameters hơn, có thể học được patterns phức tạp hơn

d) So sánh về Convergence:

1. Best Epoch:

| Model | Best Epoch | Epochs Trained | Convergence Speed |
|-------|------------|----------------|-------------------|
| MobileNetV3-Large | 25 | 30 | Nhanh nhất |
| EfficientNet-B0 | 26 | 31 | Nhanh |
| ResNet-50 | 34 | 39 | Chậm hơn |

**Phân tích**:
- MobileNetV3-Large hội tụ nhanh nhất (best epoch 25)
- ResNet-50 cần nhiều epochs hơn để đạt best performance
- Tuy nhiên, ResNet-50 đạt accuracy cao hơn đáng kể

2. Training Stability:

Dựa trên training curves:
- ResNet-50: Training ổn định, loss giảm đều, ít biến động
- EfficientNet-B0: Training ổn định, hội tụ nhanh
- MobileNetV3-Large: Training ổn định, hội tụ nhanh nhất

e) So sánh về Performance trên các Nhóm:

1. Performance trên Nấm Độc:

| Model | Avg Recall (Poisonous) | Avg Precision (Poisonous) | Avg F1 (Poisonous) |
|-------|------------------------|---------------------------|---------------------|
| **ResNet-50** | **~90.5%** | **~88.5%** | **~89.5%** |
| EfficientNet-B0 | ~89.0% | ~86.0% | ~87.5% |
| MobileNetV3-Large | ~88.0% | ~85.5% | ~86.8% |

**Phân tích**:
- ResNet-50 có recall cao nhất cho nấm độc, đạt mục tiêu >= 90%
- Tất cả models đều có recall tốt cho nấm độc, đảm bảo an toàn

2. Performance trên Nấm Ăn Được:

| Model | Avg Recall (Edible) | Avg Precision (Edible) | Avg F1 (Edible) |
|-------|---------------------|------------------------|-----------------|
| **ResNet-50** | **~91.2%** | **~93.5%** | **~92.3%** |
| EfficientNet-B0 | ~88.7% | ~91.0% | ~89.8% |
| MobileNetV3-Large | ~87.4% | ~90.5% | ~88.9% |

**Phân tích**: ResNet-50 có performance tốt nhất trên cả hai nhóm.

f) Khuyến nghị sử dụng:

1. **Production/Accuracy Priority**: **ResNet-50**
   - Accuracy cao nhất (91.59%)
   - Recall cao cho nấm độc (>= 90%)
   - Phù hợp cho ứng dụng yêu cầu độ chính xác cao

2. **Deployment/Speed Priority**: **MobileNetV3-Large**
   - Nhanh nhất (6.09 phút training, inference nhanh)
   - Model size nhỏ nhất (~4MB)
   - Accuracy vẫn chấp nhận được (87.64%)
   - Phù hợp cho mobile devices, edge computing

3. **Balance**: **EfficientNet-B0**
   - Cân bằng giữa accuracy (88.33%) và efficiency
   - Model size nhỏ (~5MB)
   - Phù hợp cho các ứng dụng cần cân bằng

g) Kết luận So sánh:

- **ResNet-50** là lựa chọn tốt nhất cho bài toán này với accuracy cao nhất (91.59%) và recall tốt cho nấm độc (>= 90%), đảm bảo an toàn cho người dùng.

- **MobileNetV3-Large** phù hợp cho deployment trên thiết bị có tài nguyên hạn chế với tốc độ nhanh và model size nhỏ.

- **EfficientNet-B0** cung cấp sự cân bằng tốt giữa accuracy và efficiency, phù hợp cho nhiều ứng dụng thực tế.

Việc so sánh này cho thấy mỗi kiến trúc có điểm mạnh riêng, và việc lựa chọn phụ thuộc vào yêu cầu cụ thể của ứng dụng.

