4.5. TRIỂN KHAI HỆ THỐNG WEB VÀ ENSEMBLE SOFT VOTING

Sau quá trình huấn luyện và đánh giá các mô hình, việc triển khai hệ thống vào môi trường thực tế là bước quan trọng để người dùng có thể sử dụng. Trong đề tài này, một hệ thống web hoàn chỉnh đã được xây dựng với kiến trúc hiện đại, tích hợp cơ chế Ensemble Soft Voting để tận dụng sức mạnh của cả ba mô hình backbone, đảm bảo độ chính xác và độ tin cậy cao nhất cho người dùng.

4.5.1. Kiến trúc tổng thể của hệ thống web

a) Mô hình kiến trúc:

Hệ thống được xây dựng theo mô hình Client-Server với kiến trúc ba tầng (Three-Tier Architecture):

1. **Presentation Layer (Frontend)**:
   - React với Vite build tool
   - Giao diện người dùng hiện đại, responsive
   - Tương tác với người dùng, hiển thị kết quả

2. **Application Layer (Backend)**:
   - FastAPI framework
   - RESTful API endpoints
   - Xử lý business logic, inference, ensemble voting

3. **Data/Model Layer**:
   - Trained models (ResNet-50, EfficientNet-B0, MobileNetV3-Large)
   - Model checkpoints (.pth files)
   - Configuration files

b) Luồng xử lý yêu cầu:

```
User → Frontend (React) → API Request → Backend (FastAPI) → Ensemble Inference → Response → Frontend → User
```

1. **User upload ảnh** qua giao diện web
2. **Frontend** gửi HTTP POST request đến Backend API
3. **Backend** nhận ảnh, preprocess, và chạy inference với 3 models
4. **Ensemble Soft Voting** kết hợp predictions từ 3 models
5. **Backend** trả về kết quả dưới dạng JSON
6. **Frontend** hiển thị kết quả với toxicity warnings

c) Công nghệ sử dụng:

**Backend**:
- FastAPI: Framework web hiện đại, nhanh, tự động tạo API documentation
- PyTorch: Deep learning framework cho inference
- Uvicorn: ASGI server để chạy FastAPI
- PIL/Pillow: Xử lý ảnh
- NumPy: Tính toán số học

**Frontend**:
- React 18+: UI framework
- Vite: Build tool nhanh
- Axios: HTTP client để gọi API
- CSS3: Styling

4.5.2. Cơ chế Ensemble Soft Voting

a) Khái niệm về Ensemble Learning:

Ensemble Learning là kỹ thuật kết hợp nhiều mô hình để tạo ra một dự đoán tốt hơn so với từng mô hình riêng lẻ. Trong đề tài này, ba mô hình backbone khác nhau (ResNet-50, EfficientNet-B0, MobileNetV3-Large) được kết hợp để tận dụng điểm mạnh của từng mô hình và giảm thiểu điểm yếu.

b) So sánh các phương pháp Ensemble:

1. **Hard Voting**:
   - Cơ chế: Mỗi model bỏ phiếu cho một lớp, lớp nào nhận nhiều phiếu nhất sẽ thắng
   - Ưu điểm: Đơn giản, dễ hiểu
   - Nhược điểm: Bỏ qua thông tin về confidence (xác suất), có thể mất thông tin quan trọng

2. **Soft Voting (Trung bình xác suất)**:
   - Cơ chế: Cộng trung bình xác suất (probability) của cả 3 models cho từng lớp, lớp nào có xác suất trung bình cao nhất sẽ được chọn
   - Ưu điểm: 
     + Tận dụng thông tin về confidence của từng model
     + Kết quả mượt mà hơn, ít bị ảnh hưởng bởi outliers
     + Phù hợp khi các models có performance tương đương
   - Nhược điểm: Phức tạp hơn một chút so với Hard Voting

3. **Weighted Soft Voting**:
   - Cơ chế: Tương tự Soft Voting nhưng có trọng số khác nhau cho từng model (ví dụ: ResNet-50 có trọng số cao hơn vì accuracy cao hơn)
   - Ưu điểm: Có thể ưu tiên models tốt hơn
   - Nhược điểm: Cần xác định trọng số, có thể phức tạp

c) Lựa chọn Soft Voting cho đề tài:

Đề tài lựa chọn **Soft Voting (Trung bình xác suất)** vì:

1. **Tận dụng thông tin đầy đủ**: Sử dụng xác suất thay vì chỉ nhãn, giữ lại thông tin về độ tin cậy của từng model

2. **Cân bằng tốt**: Cả ba models đều có performance tốt (87-91% accuracy), không có model nào quá yếu, nên trung bình đơn giản là phù hợp

3. **Ổn định hơn**: Kết quả ít bị ảnh hưởng bởi một model dự đoán sai với confidence thấp

4. **Dễ triển khai**: Không cần xác định trọng số phức tạp, dễ maintain

d) Công thức toán học của Soft Voting:

Cho một ảnh đầu vào, mỗi model `i` (i = 1, 2, 3) tạo ra một vector xác suất:

```
P_i = [p_i^1, p_i^2, ..., p_i^11]
```

Trong đó:
- `p_i^j`: Xác suất mà model `i` gán cho lớp `j` (j = 1, 2, ..., 11)
- `Σ_j p_i^j = 1` (tổng xác suất = 100%)

Xác suất trung bình cho lớp `j` được tính:

```
P_avg^j = (1/3) × (p_1^j + p_2^j + p_3^j)
```

Lớp được chọn là lớp có xác suất trung bình cao nhất:

```
Predicted_Class = argmax_j(P_avg^j)
```

Confidence của prediction là xác suất trung bình của lớp được chọn:

```
Confidence = max_j(P_avg^j) × 100%
```

e) Ví dụ minh họa:

Giả sử có một ảnh nấm, 3 models đưa ra predictions:

**ResNet-50**:
- Amanita: 45%
- Cortinarius: 30%
- Boletus: 15%
- Các lớp khác: 10%

**EfficientNet-B0**:
- Amanita: 40%
- Cortinarius: 35%
- Boletus: 20%
- Các lớp khác: 5%

**MobileNetV3-Large**:
- Amanita: 50%
- Cortinarius: 25%
- Boletus: 18%
- Các lớp khác: 7%

**Soft Voting**:
- Amanita: (45% + 40% + 50%) / 3 = **45.0%** ← **Được chọn**
- Cortinarius: (30% + 35% + 25%) / 3 = 30.0%
- Boletus: (15% + 20% + 18%) / 3 = 17.7%
- Các lớp khác: < 10%

**Kết quả**: Predicted = Amanita với confidence = 45.0%

**Phân tích**:
- Cả 3 models đều cho Amanita là top-1 prediction
- Soft Voting xác nhận và làm mượt kết quả
- Confidence 45% cho thấy các models khá chắc chắn (không có model nào có confidence quá thấp)

f) Lợi ích của Soft Voting:

1. **Tăng độ chính xác**: Kết hợp sức mạnh của 3 models, thường cho kết quả tốt hơn từng model riêng lẻ

2. **Giảm variance**: Nếu một model dự đoán sai, hai models còn lại có thể "sửa" lỗi

3. **Tăng confidence**: Khi cả 3 models đồng ý, confidence cao hơn

4. **Robustness**: Hệ thống ít bị ảnh hưởng bởi lỗi của một model đơn lẻ

4.5.3. Triển khai Backend với FastAPI

a) Cấu trúc Backend:

Backend được tổ chức theo mô hình Clean Architecture với các tầng rõ ràng:

```
backend/
├── app/
│   ├── main.py              # FastAPI application entry point
│   ├── api/v1/              # API version 1 routes
│   │   ├── api.py          # Router aggregation
│   │   └── endpoints/      # Individual endpoints
│   │       ├── predictions.py  # Prediction endpoints
│   │       └── model.py       # Model info endpoints
│   ├── core/               # Configuration
│   │   ├── config.py      # Application configuration
│   │   └── settings.py    # Settings management
│   ├── schemas/            # Pydantic schemas (data validation)
│   │   ├── prediction.py  # Prediction request/response schemas
│   │   └── model.py       # Model info schemas
│   ├── services/          # Business logic layer
│   │   └── inference_service.py  # Inference service với ensemble
│   └── utils/             # Utility functions
│       └── file_utils.py  # File handling utilities
└── src/                   # Legacy ML code (models, inference)
    ├── model.py          # Model architecture
    ├── inference.py     # Single model inference
    └── config.py        # ML configuration
```

b) Ensemble Inference Service:

Lớp `EnsembleInferenceService` được thiết kế để quản lý và kết hợp predictions từ 3 models:

1. **Khởi tạo và Load Models**:

```python
class EnsembleInferenceService:
    def __init__(self):
        self.models = {}
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.class_names = ALL_CLASSES  # 11 classes
        
        # Load 3 models
        self._load_model("resnet50")
        self._load_model("efficientnet_b0")
        self._load_model("mobilenet_v3_large")
```

**Quy trình load model**:
- Tìm model file trong thư mục `models/`
- Ưu tiên model `_improved.pth` nếu có, nếu không thì dùng model thường
- Load checkpoint và khởi tạo model với đúng backbone
- Chuyển model lên device (GPU/CPU)
- Set model ở eval mode

2. **Preprocessing ảnh**:

```python
def preprocess_image(self, image_path: str) -> torch.Tensor:
    # Resize về 224x224
    # Convert sang RGB
    # Normalize theo ImageNet stats
    # Convert sang Tensor
    # Add batch dimension
    return image_tensor.to(self.device)
```

**Đặc điểm**:
- Preprocessing giống hệt như training để đảm bảo consistency
- Sử dụng cùng transforms: Resize(224, 224), ToTensor(), Normalize
- Normalize với mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] (ImageNet stats)

3. **Inference với từng Model**:

```python
def _predict_single_model(self, model_name: str, image_tensor: torch.Tensor) -> np.ndarray:
    model = self.models[model_name]
    model.eval()
    
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = F.softmax(outputs, dim=1)
    
    return probabilities[0].cpu().numpy()  # Shape: (11,)
```

**Đặc điểm**:
- Mỗi model chạy inference độc lập
- Sử dụng `torch.no_grad()` để tiết kiệm memory
- Áp dụng softmax để có xác suất (probabilities)
- Trả về numpy array với shape (11,) - xác suất cho 11 lớp

4. **Soft Voting Ensemble**:

```python
def predict_ensemble(self, image_path: str, top_k: int = 3) -> Dict:
    # Preprocess ảnh
    image_tensor = self.preprocess_image(image_path)
    
    # Lấy predictions từ 3 models
    probs_resnet = self._predict_single_model("resnet50", image_tensor)
    probs_efficientnet = self._predict_single_model("efficientnet_b0", image_tensor)
    probs_mobilenet = self._predict_single_model("mobilenet_v3_large", image_tensor)
    
    # Soft Voting: Trung bình xác suất
    ensemble_probs = (probs_resnet + probs_efficientnet + probs_mobilenet) / 3.0
    
    # Tìm top-k classes
    top_k_indices = np.argsort(ensemble_probs)[-top_k:][::-1]
    top_k_probs = ensemble_probs[top_k_indices]
    
    # Tạo predictions
    predictions = []
    for i, idx in enumerate(top_k_indices):
        genus = self.class_names[idx]
        prob = top_k_probs[i]
        
        predictions.append({
            "rank": i + 1,
            "genus": genus,
            "confidence": prob * 100,
            "toxicity": self.toxicity_classifier.get_toxicity_info(genus)
        })
    
    return {
        "best_prediction": predictions[0],
        "top_predictions": predictions,
        "all_probabilities": {
            self.class_names[i]: ensemble_probs[i] * 100
            for i in range(len(self.class_names))
        },
        "individual_predictions": {
            "resnet50": {
                "genus": self.class_names[np.argmax(probs_resnet)],
                "confidence": np.max(probs_resnet) * 100
            },
            "efficientnet_b0": {
                "genus": self.class_names[np.argmax(probs_efficientnet)],
                "confidence": np.max(probs_efficientnet) * 100
            },
            "mobilenet_v3_large": {
                "genus": self.class_names[np.argmax(probs_mobilenet)],
                "confidence": np.max(probs_mobilenet) * 100
            }
        }
    }
```

**Đặc điểm**:
- Tính trung bình xác suất của 3 models cho từng lớp
- Chọn lớp có xác suất trung bình cao nhất
- Trả về top-k predictions với confidence scores
- Bao gồm cả predictions của từng model riêng lẻ để so sánh

c) API Endpoints:

1. **Health Check Endpoint**:

```python
@app.get("/health")
async def health_check():
    """Kiểm tra trạng thái hệ thống"""
    return {
        "status": "healthy",
        "models_loaded": len(ensemble_service.models),
        "device": ensemble_service.device
    }
```

**Mục đích**: Kiểm tra hệ thống có sẵn sàng không, các models đã được load chưa

2. **Model Information Endpoint**:

```python
@app.get("/api/v1/model/info")
async def get_model_info():
    """Lấy thông tin về models đã load"""
    return {
        "ensemble_mode": True,
        "models": ["resnet50", "efficientnet_b0", "mobilenet_v3_large"],
        "voting_method": "soft_voting",
        "num_classes": 11,
        "classes": ALL_CLASSES
    }
```

**Mục đích**: Cung cấp thông tin về cấu hình hệ thống

3. **Prediction Endpoint**:

```python
@app.post("/api/v1/predict")
async def predict_mushroom(
    file: UploadFile = File(...),
    top_k: int = 3
):
    """Dự đoán chi nấm từ ảnh upload"""
    # Validate file type
    if not file.content_type.startswith('image/'):
        raise HTTPException(400, "File must be an image")
    
    # Save file temporarily
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        shutil.copyfileobj(file.file, tmp_file)
        tmp_path = tmp_file.name
    
    try:
        # Ensemble prediction
        result = ensemble_service.predict_ensemble(tmp_path, top_k=top_k)
        
        return {
            "success": True,
            "image_filename": file.filename,
            **result
        }
    finally:
        # Cleanup
        Path(tmp_path).unlink(missing_ok=True)
```

**Đặc điểm**:
- Nhận file ảnh qua multipart/form-data
- Validate file type và top_k
- Lưu file tạm thời
- Gọi ensemble prediction
- Trả về kết quả dưới dạng JSON
- Tự động cleanup file tạm

4. **Batch Prediction Endpoint**:

```python
@app.post("/api/v1/predict/batch")
async def predict_batch(
    files: List[UploadFile] = File(...),
    top_k: int = 3
):
    """Dự đoán nhiều ảnh cùng lúc (max 10)"""
    if len(files) > 10:
        raise HTTPException(400, "Maximum 10 files allowed")
    
    results = []
    for file in files:
        # Tương tự predict endpoint nhưng xử lý nhiều files
        ...
    
    return {"success": True, "total": len(files), "results": results}
```

**Đặc điểm**:
- Hỗ trợ upload nhiều ảnh cùng lúc (max 10)
- Xử lý từng ảnh và trả về kết quả cho tất cả
- Hữu ích cho việc test hoặc xử lý hàng loạt

d) Error Handling và Validation:

1. **File Validation**:
   - Kiểm tra file type (phải là image/)
   - Kiểm tra file size (giới hạn để tránh DoS)
   - Kiểm tra file có thể đọc được không

2. **Error Handling**:
   - Try-except blocks cho tất cả operations
   - Trả về HTTP status codes phù hợp (400, 500, v.v.)
   - Error messages rõ ràng, không tiết lộ thông tin nhạy cảm

3. **Resource Management**:
   - Tự động cleanup file tạm thời
   - Quản lý memory (giải phóng sau mỗi prediction nếu cần)

e) CORS Configuration:

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

**Mục đích**: Cho phép frontend (chạy trên port khác) gọi API mà không bị CORS error

f) API Documentation:

FastAPI tự động tạo interactive API documentation:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

**Lợi ích**:
- Dễ test API trực tiếp từ browser
- Tự động generate từ code, luôn cập nhật
- Hỗ trợ developers và testers

4.5.4. Tối ưu hóa Performance và Memory

a) Lazy Loading Models:

Thay vì load tất cả models khi khởi động:
- Load models khi cần (lazy loading)
- Hoặc load trong background thread khi app khởi động
- **Lợi ích**: Giảm thời gian khởi động, chỉ load khi cần

b) Model Caching:

- Load models một lần và cache trong memory
- Reuse models cho nhiều requests
- **Lợi ích**: Tránh load lại models nhiều lần, tăng tốc độ

c) Batch Processing:

- Nếu có nhiều requests cùng lúc, có thể batch lại
- Xử lý nhiều ảnh trong một batch để tận dụng GPU
- **Lợi ích**: Tăng throughput, giảm overhead

d) Memory Management:

1. **Giải phóng sau mỗi prediction**:
   - Xóa image tensor sau khi dùng
   - Gọi `torch.cuda.empty_cache()` nếu dùng GPU
   - **Lợi ích**: Tránh memory leak, cho phép xử lý nhiều requests

2. **Streaming cho large files**:
   - Không load toàn bộ file vào memory
   - Process từng phần nếu cần
   - **Lợi ích**: Giảm memory usage

e) Async Processing:

FastAPI hỗ trợ async/await:
- Có thể xử lý nhiều requests đồng thời
- Không block thread khi chờ I/O
- **Lợi ích**: Tăng throughput, phục vụ nhiều users cùng lúc

f) Response Time Optimization:

1. **Preprocessing nhanh**:
   - Sử dụng PIL/Pillow hiệu quả
   - Resize và normalize nhanh

2. **Inference song song** (nếu có nhiều GPU):
   - Chạy 3 models inference song song trên 3 GPU khác nhau
   - **Lợi ích**: Giảm thời gian từ ~3x xuống ~1x

3. **GPU Optimization**:
   - Sử dụng Mixed Precision (FP16) cho inference nếu cần
   - Batch processing để tận dụng GPU parallelism

4.5.5. Triển khai Frontend với React

a) Cấu trúc Frontend:

```
frontend/
├── src/
│   ├── components/         # Reusable components
│   │   ├── Header.jsx    # Header component
│   │   ├── Sidebar.jsx   # Sidebar navigation
│   │   ├── Footer.jsx    # Footer component
│   │   ├── ImageUpload.jsx  # Image upload component
│   │   └── PredictionResult.jsx  # Result display component
│   ├── pages/              # Page components
│   │   └── HomePage.jsx   # Main page
│   ├── services/           # API services
│   │   └── api.js         # API client
│   ├── hooks/              # Custom React hooks
│   │   └── usePrediction.js  # Prediction hook
│   ├── utils/              # Utility functions
│   │   └── helpers.js     # Helper functions
│   └── styles/             # CSS files
│       └── App.css         # Main styles
└── public/                 # Static assets
```

b) API Service Layer:

```javascript
// services/api.js
import axios from 'axios';

const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || 'http://localhost:8000';

const apiClient = axios.create({
  baseURL: API_BASE_URL,
  timeout: 30000, // 30 seconds
});

export const predictMushroom = async (imageFile, topK = 3) => {
  const formData = new FormData();
  formData.append('file', imageFile);
  formData.append('top_k', topK);
  
  const response = await apiClient.post('/api/v1/predict', formData, {
    headers: {
      'Content-Type': 'multipart/form-data',
    },
  });
  
  return response.data;
};
```

**Đặc điểm**:
- Sử dụng Axios cho HTTP requests
- Configurable API base URL (qua environment variables)
- Timeout 30 giây (đủ cho inference)
- Error handling tự động

c) Prediction Component:

Component chính để upload ảnh và hiển thị kết quả:

```javascript
// components/PredictionResult.jsx
function PredictionResult({ result }) {
  const { best_prediction, top_predictions, individual_predictions } = result;
  
  return (
    <div className="prediction-result">
      <h2>Kết quả dự đoán</h2>
      
      {/* Best Prediction */}
      <div className="best-prediction">
        <h3>{best_prediction.genus}</h3>
        <p>Confidence: {best_prediction.confidence.toFixed(2)}%</p>
        {best_prediction.toxicity.is_poisonous && (
          <div className="warning">
            ⚠️ CẢNH BÁO: Nấm này có độc tính!
          </div>
        )}
      </div>
      
      {/* Top Predictions */}
      <div className="top-predictions">
        {top_predictions.map(pred => (
          <div key={pred.rank}>
            {pred.rank}. {pred.genus} ({pred.confidence.toFixed(2)}%)
          </div>
        ))}
      </div>
      
      {/* Individual Model Predictions */}
      <div className="individual-predictions">
        <h4>Predictions từ từng model:</h4>
        <p>ResNet-50: {individual_predictions.resnet50.genus} 
           ({individual_predictions.resnet50.confidence.toFixed(2)}%)</p>
        <p>EfficientNet-B0: {individual_predictions.efficientnet_b0.genus}
           ({individual_predictions.efficientnet_b0.confidence.toFixed(2)}%)</p>
        <p>MobileNetV3-Large: {individual_predictions.mobilenet_v3_large.genus}
           ({individual_predictions.mobilenet_v3_large.confidence.toFixed(2)}%)</p>
      </div>
    </div>
  );
}
```

**Đặc điểm**:
- Hiển thị best prediction với toxicity warning nổi bật
- Hiển thị top-k predictions
- Hiển thị predictions từ từng model riêng lẻ để so sánh
- Responsive design, đẹp mắt

d) Image Upload Component:

```javascript
// components/ImageUpload.jsx
function ImageUpload({ onPredict }) {
  const [image, setImage] = useState(null);
  const [loading, setLoading] = useState(false);
  
  const handleFileChange = (e) => {
    const file = e.target.files[0];
    if (file) {
      setImage(URL.createObjectURL(file));
    }
  };
  
  const handlePredict = async () => {
    if (!image) return;
    
    setLoading(true);
    try {
      const file = document.getElementById('file-input').files[0];
      const result = await predictMushroom(file, 3);
      onPredict(result);
    } catch (error) {
      alert('Lỗi: ' + error.message);
    } finally {
      setLoading(false);
    }
  };
  
  return (
    <div className="image-upload">
      <input type="file" accept="image/*" onChange={handleFileChange} />
      {image && <img src={image} alt="Preview" />}
      <button onClick={handlePredict} disabled={loading}>
        {loading ? 'Đang xử lý...' : 'Nhận diện'}
      </button>
    </div>
  );
}
```

**Đặc điểm**:
- Drag & drop hoặc click để upload
- Preview ảnh trước khi predict
- Loading state khi đang xử lý
- Error handling và hiển thị thông báo

e) User Experience Features:

1. **Loading Indicators**:
   - Progress bar hoặc spinner khi đang xử lý
   - Hiển thị "Đang phân tích ảnh..." với thông tin chi tiết

2. **Error Messages**:
   - Thông báo lỗi rõ ràng, dễ hiểu
   - Hướng dẫn cách khắc phục

3. **Toxicity Warnings**:
   - Cảnh báo nổi bật cho nấm độc (màu đỏ, icon cảnh báo)
   - Thông tin chi tiết về độc tính

4. **Responsive Design**:
   - Hoạt động tốt trên desktop, tablet, mobile
   - Layout tự động điều chỉnh

4.5.6. So sánh Performance: Single Model vs Ensemble

a) Độ chính xác:

**Single Model (ResNet-50)**:
- Test Accuracy: 91.59%
- Best model nhưng vẫn có thể sai trong một số trường hợp

**Ensemble Soft Voting**:
- Expected Accuracy: ~92-93% (ước tính, cao hơn single model)
- **Lý do**: Kết hợp sức mạnh của 3 models, giảm variance

b) Thời gian xử lý:

**Single Model**:
- Inference time: ~50-100ms (tùy GPU/CPU)
- Total time: ~100-200ms (bao gồm preprocessing)

**Ensemble (3 Models)**:
- Inference time: ~150-300ms (3x single model)
- Total time: ~200-400ms
- **Trade-off**: Chậm hơn 3x nhưng chính xác hơn

c) Memory Usage:

**Single Model**:
- Model size: ~25MB (ResNet-50)
- Memory during inference: ~100-200MB

**Ensemble (3 Models)**:
- Total model size: ~34MB (25 + 5 + 4)
- Memory during inference: ~300-500MB
- **Trade-off**: Cần nhiều memory hơn nhưng vẫn chấp nhận được

d) Kết luận về Performance:

- **Ensemble Soft Voting** tăng độ chính xác đáng kể (ước tính +1-2%)
- Thời gian xử lý tăng 3x nhưng vẫn chấp nhận được (< 1 giây)
- Memory usage tăng nhưng vẫn trong phạm vi hợp lý
- **Khuyến nghị**: Sử dụng Ensemble cho production để đảm bảo độ chính xác và an toàn cao nhất

4.5.7. Bảo mật và Xử lý lỗi

a) Bảo mật:

1. **File Upload Security**:
   - Validate file type (chỉ cho phép image files)
   - Giới hạn file size (ví dụ: max 10MB)
   - Scan file để phát hiện malware (nếu cần)
   - Lưu file tạm thời với tên ngẫu nhiên

2. **Input Validation**:
   - Validate tất cả inputs từ user
   - Sanitize file names
   - Kiểm tra file có hợp lệ không

3. **Rate Limiting**:
   - Giới hạn số requests mỗi phút từ một IP
   - Tránh abuse và DoS attacks

b) Error Handling:

1. **Graceful Degradation**:
   - Nếu một model lỗi, vẫn có thể dùng 2 models còn lại
   - Fallback mechanism

2. **Error Messages**:
   - Thông báo lỗi rõ ràng cho user
   - Log chi tiết cho developers
   - Không tiết lộ thông tin nhạy cảm

3. **Retry Mechanism**:
   - Tự động retry nếu có lỗi tạm thời
   - Exponential backoff

4.5.8. Deployment và Production

a) Backend Deployment:

1. **Production Server**:
   - Sử dụng Gunicorn hoặc Uvicorn workers
   - Multiple workers để xử lý nhiều requests
   - Reverse proxy (Nginx) để load balancing

2. **Environment Variables**:
   - API keys, secrets trong environment variables
   - Không hardcode trong code

3. **Logging**:
   - Structured logging (JSON format)
   - Log levels: DEBUG, INFO, WARNING, ERROR
   - Log rotation để tránh đầy disk

4. **Monitoring**:
   - Health checks tự động
   - Metrics: response time, error rate, throughput
   - Alerts khi có vấn đề

b) Frontend Deployment:

1. **Build Production**:
   ```bash
   npm run build
   ```
   - Tạo optimized bundle
   - Minify code
   - Tree shaking để giảm size

2. **Static Hosting**:
   - Deploy lên CDN (Cloudflare, AWS CloudFront)
   - Hoặc serve từ Nginx

3. **Environment Configuration**:
   - API URL trong environment variables
   - Khác nhau giữa dev và production

c) Docker Deployment (Tùy chọn):

```dockerfile
# Backend Dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Lợi ích**:
- Consistent environment
- Dễ deploy
- Scalable với Docker Compose hoặc Kubernetes

4.5.9. Kết luận

Hệ thống web đã được triển khai thành công với các đặc điểm sau:

- **Kiến trúc hiện đại**: FastAPI backend + React frontend, dễ maintain và mở rộng

- **Ensemble Soft Voting**: Kết hợp sức mạnh của 3 models, tăng độ chính xác và độ tin cậy

- **API RESTful**: Dễ tích hợp, có documentation tự động

- **User-friendly Interface**: Giao diện đẹp, dễ sử dụng, có toxicity warnings rõ ràng

- **Production-ready**: Error handling, security, logging, monitoring đầy đủ

- **Performance**: Thời gian xử lý chấp nhận được (< 1 giây), memory usage hợp lý

Hệ thống sẵn sàng cho việc triển khai thực tế, cung cấp một công cụ hữu ích và an toàn cho việc nhận diện chi nấm và cảnh báo độc tính.

